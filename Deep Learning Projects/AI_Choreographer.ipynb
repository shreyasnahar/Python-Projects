{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Choreographer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz1TK4Y8QQ9v",
        "outputId": "b0e8b55f-1254-4d38-c7b0-753c49eb7d47"
      },
      "source": [
        "!pip install google-cloud\n",
        "!pip install google-cloud-videointelligence\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Requirement already satisfied: google-cloud-videointelligence in /usr/local/lib/python3.7/dist-packages (2.3.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-videointelligence) (21.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-videointelligence) (1.26.3)\n",
            "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-videointelligence) (1.19.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (3.17.3)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (1.34.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (1.53.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (1.39.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-videointelligence) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-videointelligence) (2021.5.30)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOqVLtNF9PI1"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as videointelligence\n",
        "import os\n",
        "import io\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/Google-cloud-video-intelligence-api-file/video-intelligence-325504-fc7cd33ccbf8.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceQQKNC-JQQ"
      },
      "source": [
        "#Detect person including attributes from every segment of video file\n",
        "def detect_person(local_file_path):\n",
        "    client = videointelligence.VideoIntelligenceServiceClient()\n",
        "\n",
        "    with io.open(local_file_path, \"rb\") as f:\n",
        "        input_content = f.read()\n",
        "\n",
        "    # Configure the request\n",
        "    config = videointelligence.types.PersonDetectionConfig(\n",
        "        include_bounding_boxes=True,\n",
        "        include_attributes=True,\n",
        "        include_pose_landmarks=True,\n",
        "    )\n",
        "    context = videointelligence.types.VideoContext(person_detection_config=config)\n",
        "\n",
        "    # Start the asynchronous request\n",
        "    operation = client.annotate_video(\n",
        "        request={\n",
        "            \"features\": [videointelligence.Feature.PERSON_DETECTION],\n",
        "            \"input_content\": input_content,\n",
        "            \"video_context\": context,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(\"\\nProcessing video for person detection annotations.\")\n",
        "    result = operation.result(timeout=300)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZtFPAIZ-zju"
      },
      "source": [
        "#Person is detected by recognizing positions of various body parts\n",
        "#Relative position of every body part can be used as metadata of that segment \n",
        "def get_relative_measures(response1):\n",
        "  motion_detection_data = []\n",
        "  for annotation in response1.annotation_results[0].person_detection_annotations:\n",
        "    for track in annotation.tracks:\n",
        "      for timestamped_obj in track.timestamped_objects:\n",
        "        land_marks_coordinates = []\n",
        "        for land_mark in timestamped_obj.landmarks:\n",
        "          land_marks_coordinates.append([land_mark.point.x,land_mark.point.y])\n",
        "        relative_measures = []\n",
        "        for i in range(len(land_marks_coordinates)):\n",
        "          for j in range(i+1,len(land_marks_coordinates)):\n",
        "            relative_measures.append([land_marks_coordinates[i][0]-land_marks_coordinates[j][0],land_marks_coordinates[i][1]-land_marks_coordinates[j][1]])\n",
        "        motion_detection_data.append(relative_measures)\n",
        "  return motion_detection_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBrSxpgr_e9N"
      },
      "source": [
        "#Manhattan distance between relative position of same body part in repsective segment can be used as metric for determining body posture similarity\n",
        "def motion_difference_score(motion_data1,motion_data2):\n",
        "  result = 0\n",
        "  count = 0\n",
        "  for segment1 in motion_data1:\n",
        "    similarity_score = 1e9\n",
        "    for segment2 in motion_data2:\n",
        "      if len(segment1)!=len(segment2):\n",
        "        continue \n",
        "      score = 0\n",
        "      for i in range(len(segment1)):\n",
        "        score+=(abs(segment1[i][0]-segment2[i][0]) + abs(segment1[i][1]-segment2[i][1]))/2 \n",
        "      similarity_score = min(similarity_score,score)\n",
        "    count+=1\n",
        "    result+=similarity_score \n",
        "  return result/count "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq_miA2D8-kh",
        "outputId": "e1c4e6d7-61b5-4be5-f543-dd4caf2bcb64"
      },
      "source": [
        "realtive_measures_data = []\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/dance-videos/\"\n",
        "for video_path in os.listdir(root_dir):\n",
        "  response = detect_person(root_dir + video_path)\n",
        "  relative_measures = get_relative_measures(response)\n",
        "  realtive_measures_data.append([os.path.basename(video_path),relative_measures])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing video for person detection annotations.\n",
            "\n",
            "Processing video for person detection annotations.\n",
            "\n",
            "Processing video for person detection annotations.\n",
            "\n",
            "Processing video for person detection annotations.\n",
            "\n",
            "Processing video for person detection annotations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL9MmXvS-b1p",
        "outputId": "a90dff89-ac3a-40d9-c34c-f629a2454909"
      },
      "source": [
        "threshold = 10.0\n",
        "\n",
        "for name1,msr1 in realtive_measures_data:\n",
        "  for name2,msr2 in realtive_measures_data:\n",
        "    score = motion_difference_score(msr1,msr2)\n",
        "    if score<=threshold:\n",
        "      print(f\"{name1}  VS  {name2}  ==>  {score}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen_results_1.mp4  VS  gen_results_1.mp4  ==>  0.0\n",
            "gen_results_1.mp4  VS  gen_results_3.mp4  ==>  4.737978315940409\n",
            "gen_results_1.mp4  VS  gen_results_2.mp4  ==>  4.025387151900566\n",
            "gen_results_1.mp4  VS  gen_results_4.mp4  ==>  3.7278370367306652\n",
            "gen_results_1.mp4  VS  gen_results_5.mp4  ==>  3.1645116422212487\n",
            "gen_results_3.mp4  VS  gen_results_1.mp4  ==>  4.679918041383779\n",
            "gen_results_3.mp4  VS  gen_results_3.mp4  ==>  0.0\n",
            "gen_results_3.mp4  VS  gen_results_2.mp4  ==>  3.6118425877005964\n",
            "gen_results_3.mp4  VS  gen_results_4.mp4  ==>  3.0655248048128905\n",
            "gen_results_3.mp4  VS  gen_results_5.mp4  ==>  3.718429116959925\n",
            "gen_results_2.mp4  VS  gen_results_2.mp4  ==>  0.0\n",
            "gen_results_2.mp4  VS  gen_results_4.mp4  ==>  3.2787154484234873\n",
            "gen_results_2.mp4  VS  gen_results_5.mp4  ==>  3.7005139321821634\n",
            "gen_results_4.mp4  VS  gen_results_2.mp4  ==>  3.232380141343536\n",
            "gen_results_4.mp4  VS  gen_results_4.mp4  ==>  0.0\n",
            "gen_results_4.mp4  VS  gen_results_5.mp4  ==>  3.5909635134298226\n",
            "gen_results_5.mp4  VS  gen_results_5.mp4  ==>  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2VM4S3mAmmQ"
      },
      "source": [
        "\"More to Come\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv_mGuX3COnJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}